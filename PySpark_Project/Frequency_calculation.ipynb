{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install PySpark library (!pip install pyspark)\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install findspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anea/.local/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder\\\n",
    "                  .master(\"local\")\\\n",
    "                  .appName(\"WordCount\")\\\n",
    "                  .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_de=sc.textFile(\"/home/anea/HTW_SS23/Prog_Alg/Spark_Project/PySpark_Project/German/Ein_Kampf_um_Rom_Felix_Dahn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_de.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_flat=text_de.flatMap(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_flat.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_flat=text_de.flatMap(lambda x: x.split(' '))\\\n",
    "                 .map(lambda x: (x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_flat.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_flat=text_de.flatMap(lambda x: x.split(' '))\\\n",
    "                 .map(lambda x: (x,1))\\\n",
    "                 .reduceByKey(lambda x,y : x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_flat.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFile = spark.read.text(\"/home/anea/HTW_SS23/Prog_Alg/Spark_Project/PySpark_Project/German/Ein_Kampf_um_Rom_Felix_Dahn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592,\n",
       " ['a',\n",
       "  'ab',\n",
       "  'aber',\n",
       "  'ach',\n",
       "  'acht',\n",
       "  'achte',\n",
       "  'achten',\n",
       "  'achter',\n",
       "  'achtes',\n",
       "  'ag',\n",
       "  'alle',\n",
       "  'allein',\n",
       "  'allem',\n",
       "  'allen',\n",
       "  'aller'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords\n",
    "with open(\"stop_words_german.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    stopwords = text.splitlines()\n",
    "\n",
    "len(stopwords), stopwords[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|       [Felix, Dahn]|\n",
      "|                  []|\n",
      "|[EIN, KAMPF, UM, ...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "lines = textFile.select(split(textFile.value, \" \").alias(\"line\"))\n",
    "lines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|     Felix|\n",
      "|      Dahn|\n",
      "|          |\n",
      "|       EIN|\n",
      "|     KAMPF|\n",
      "|        UM|\n",
      "|       ROM|\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|    ERSTES|\n",
      "|     BUCH:|\n",
      "|THEODERICH|\n",
      "+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "words = lines.select(explode(col(\"line\")).alias(\"word\"))\n",
    "words.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| word_lower|\n",
      "+-----------+\n",
      "|      felix|\n",
      "|       dahn|\n",
      "|           |\n",
      "|        ein|\n",
      "|      kampf|\n",
      "|         um|\n",
      "|        rom|\n",
      "|           |\n",
      "|           |\n",
      "|           |\n",
      "|           |\n",
      "|           |\n",
      "|     erstes|\n",
      "|      buch:|\n",
      "| theoderich|\n",
      "|           |\n",
      "|           |\n",
      "|           |\n",
      "|Â»dietericus|\n",
      "|         de|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "words_lower = words.select(lower(col(\"word\")).alias(\"word_lower\"))\n",
    "words_lower.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|     felix|\n",
      "|      dahn|\n",
      "|          |\n",
      "|       ein|\n",
      "|     kampf|\n",
      "|        um|\n",
      "|       rom|\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|    erstes|\n",
      "|      buch|\n",
      "|theoderich|\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|dietericus|\n",
      "|        de|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col(\"word_lower\"), \"[a-z]+\", 0).alias(\"word\")\n",
    ")\n",
    "\n",
    "words_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      word|\n",
      "+----------+\n",
      "|     felix|\n",
      "|      dahn|\n",
      "|       ein|\n",
      "|     kampf|\n",
      "|        um|\n",
      "|       rom|\n",
      "|    erstes|\n",
      "|      buch|\n",
      "|theoderich|\n",
      "|dietericus|\n",
      "|        de|\n",
      "|     berne|\n",
      "|        de|\n",
      "|       quo|\n",
      "|   cantant|\n",
      "|   rustici|\n",
      "|     usque|\n",
      "|     hodie|\n",
      "|    erstes|\n",
      "|   kapitel|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_nonull = words_clean.filter(col(\"word\") != \"\")\n",
    "words_nonull.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315942, 133805)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_without_stopwords = words_nonull.filter(\n",
    "    ~words_nonull.word.isin(stopwords))\n",
    "\n",
    "words_count_before_removing = words_nonull.count()\n",
    "words_count_after_removing = words_without_stopwords.count()\n",
    "\n",
    "words_count_before_removing, words_count_after_removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = (words_without_stopwords.groupby(\"word\")\n",
    "               .count()\n",
    "               .orderBy(\"count\", ascending=False)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|cethegus| 1066|\n",
      "|   goten|  814|\n",
      "|  sprach|  728|\n",
      "|     ber|  717|\n",
      "|    rief|  665|\n",
      "|     sch|  581|\n",
      "|     rom|  571|\n",
      "| belisar|  555|\n",
      "|     wei|  525|\n",
      "|      mu|  517|\n",
      "|      pr|  503|\n",
      "|      st|  435|\n",
      "|     gro|  434|\n",
      "|witichis|  429|\n",
      "|  totila|  421|\n",
      "|    hand|  395|\n",
      "|    teja|  393|\n",
      "|   stadt|  364|\n",
      "|      gl|  329|\n",
      "|  narses|  311|\n",
      "+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank = 20\n",
    "words_count.show(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
